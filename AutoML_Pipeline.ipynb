{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "import torch\n",
    "from autogluon.tabular import TabularDataset, TabularPredictor\n",
    "\n",
    "def setup_seed(seed = 3407):\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "\n",
    "    np.random.seed(seed)\n",
    "    random.seed(seed)\n",
    "\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    torch.backends.cudnn.enabled = False\n",
    "\n",
    "setup_seed()\n",
    "\n",
    "train_data = TabularDataset('Path to traning cohort')\n",
    "\n",
    "drop_colums = ['ID']\n",
    "train_data = train_data.drop(columns=drop_colums)\n",
    "\n",
    "label = 'Label'\n",
    "metric = 'roc_auc'\n",
    "# time_limit = 1200\n",
    "save_path = 'Path to save your model'\n",
    "\n",
    "# predictor = TabularPredictor(label=label, path=save_path, eval_metric = metric).fit(train_data, presets='best_quality', time_limit=time_limit)\n",
    "predictor = TabularPredictor(label=label, path=save_path, eval_metric = metric).fit(train_data, presets='medium_quality')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = predictor.fit_summary(show_plot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = TabularDataset('Path to testing cohort').drop(columns=drop_colums)\n",
    "\n",
    "label = 'Label'\n",
    "y_test = test_data[label]\n",
    "test_data_nolab = test_data.drop(columns=[label])\n",
    "test_data_nolab.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictor = TabularPredictor.load(save_path)\n",
    "y_pred_probe = predictor.predict_proba(test_data_nolab)\n",
    "print(\"Predictions:  \\n\", y_pred_probe)\n",
    "perf = predictor.evaluate_predictions(y_true=y_test, y_pred=y_pred_probe, auxiliary_metrics=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictor.leaderboard(train_data, silent=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictor.feature_importance(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictor.leaderboard(test_data, silent=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictor.feature_importance(test_data)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
